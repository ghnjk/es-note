# ES数据持久化与查询可见性

## 动态索引过程。内存缓存与提交点

Elasticsearch底层依赖的Lucene，引入了 per-segment search 的概念。一个段\(segment\)是有 完整功能的倒排索引，但是现在Lucene中的索引指的是段的集合，再加上提交点\(commit point，包括所有段的文件\)，如图1所示。新的文档，在被写入磁盘的段之前，首先写入内存 区的索引缓存，如图2、图3所示。

图1：一个提交点和三个索引的Lucene

![](../.gitbook/assets/image%20%2824%29.png)

一个 per-segment search 如下工作:

* 新的文档首先写入内存区的索引缓存。
* 不时，这些buffer被提交：
  * 一个新的段——额外的倒排索引——写入磁盘。
  * 新的提交点写入磁盘，包括新段的名称。
  * 磁盘是fsync’ed\(文件同步\)——所有写操作等待文件系统缓存同步到磁盘，确保它们可以被物理写入。
* 新段被打开，它包含的文档可以被检索
* 内存的缓存被清除，等待接受新的文档

图2：内存缓存区有即将提交文档的Lucene索引

![](../.gitbook/assets/image%20%2811%29.png)

图3：提交后，新的段加到了提交点，缓存被清空

![](../.gitbook/assets/image%20%2817%29.png)

当一个请求被接受，所有段依次查询。所有段上的Term统计信息被聚合，确保每个term和文 档的相关性被正确计算。通过这种方式，新的文档以较小的代价加入索引。

## 近实时搜索。段文件落盘与文件缓冲区

因为 per-segment search 机制，索引和搜索一个文档之间是有延迟的。新的文档会在几分钟 内可以搜索，但是这依然不够快。

磁盘是瓶颈。提交一个新的段到磁盘需要 fsync 操作，确保段被物理地写入磁盘，即时电源 失效也不会丢失数据。但是 fsync 是昂贵的，它不能在每个文档被索引的时就触

所以需要一种更轻量级的方式使新的文档可以被搜索，这意味这移除 fsync 

位于Elasticsearch和磁盘间的是文件系统缓存。如前所说，在内存索引缓存中的文档（图1） 被写入新的段（图2），但是新的段首先写入文件系统缓存，这代价很低，之后会被同步到磁 盘，这个代价很大。但是一旦一个文件被缓存，它也可以被打开和读取，就像其他文件一 样。

图1：内存缓存区有新文档的Lucene索引

![](../.gitbook/assets/image%20%2822%29.png)

Lucene允许新段写入打开，好让它们包括的文档可搜索，而不用执行一次全量提交。这是比 提交更轻量的过程，可以经常操作，而不会影响性能。

图2：缓存内容已经写到段中，但是还没提交 refeash API

![](../.gitbook/assets/image%20%286%29.png)

## refresh api

在Elesticsearch中，这种写入打开一个新段的轻量级过程，叫做refresh。默认情况下，每个 分片每秒自动刷新一次。这就是为什么说Elasticsearch是近实时的搜索了：文档的改动不会 立即被搜索，但是会在一秒内可见。

这会困扰新用户：他们索引了个文档，尝试搜索它，但是搜不到。解决办法就是执行一次手 动刷新，通过API:

```text
POST /_refresh
POST /blogs/_refresh
```

不是所有的用户都需要每秒刷新一次。也许你使用ES索引百万日志文件，你更想要优化索引 的速度，而不是进实时搜索。你可以通过修改配置项 refresh\_interval 减少刷新的频率：

```text
PUT /my_logs
{
    "settings": {
        "refresh_interval": "30s" <1>
    }
}
```

## translog与数据持久化变更

没用 fsync 同步文件系统缓存到磁盘，我们不能确保电源失效，甚至正常退出应用后，数据 的安全。为了ES的可靠性，需要确保变更持久化到磁盘。

我们说过一次全提交同步段到磁盘，写提交点，这会列出所有的已知的段。在重启，或重新 打开索引时，ES使用这次提交点决定哪些段属于当前的分片。

当我们通过每秒的刷新获得近实时的搜索，我们依然需要定时地执行全提交确保能从失败中 恢复。但是提交之间的文档怎么办？我们也不想丢失它们。

ES增加了事务日志（ translog ），来记录每次操作。有了事务日志，过程现在如下：

一、 当一个文档被索引，它被加入到内存缓存，同时加到事务日志。

图1：新的文档加入到内存缓存，同时写入事务日志 2.

![](../.gitbook/assets/image%20%2819%29.png)

二、 refresh使得分片的进入如下图描述的状态。每秒分片都进行refeash

* 内存缓冲区的文档写入到段中，但没有fsync。
* 段被打开，使得新的文档可以搜索。
* 缓存被清除

图2：经过一次refresh，缓存被清除，但事务日志没有

![](../.gitbook/assets/image%20%2814%29.png)

三、 随着更多的文档加入到缓存区，写入日志，这个过程会继续

图3：事务日志会记录增长的文档 4.

![](../.gitbook/assets/image%20%287%29.png)

四、 不时地，比如日志很大了，新的日志会创建，会进行一次全提交：

* 内存缓存区的所有文档会写入到新段中。
* 清除缓存
* 一个提交点写入硬盘
* 文件系统缓存通过fsync操作flush到硬盘
* 事务日志被清除

事务日志记录了没有flush到硬盘的所有操作。当故障重启后，ES会用最近一次提交点从硬盘 恢复所有已知的段，并且从日志里恢复所有的操作。

事务日志还用来提供实时的CRUD操作。当你尝试用ID进行CRUD时，它在检索相关段内的文 档前会首先检查日志最新的改动。这意味着ES可以实时地获取文档的最新版本。

图4：flush过后，段被全提交，事务日志清除

![](../.gitbook/assets/image%20%281%29.png)

## flush api

在ES中，进行一次提交并删除事务日志的操作叫做 flush 。分片每30分钟，或事务日志过大 会进行一次flush操作。

flush API 可用来进行一次手动flush：

```text
POST /blogs/_flush 
POST /_flush?wait_for_ongoing
```

你很少需要手动 flush ，通常自动的就够了

当你要重启或关闭一个索引，flush该索引是很有用的。当ES尝试恢复或者重新打开一个索引 时，它必须重放所有事务日志中的操作，所以日志越小，恢复速度越快。



